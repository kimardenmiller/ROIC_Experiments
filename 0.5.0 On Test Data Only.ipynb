{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Feature Names: \n ['total yield' 'ms debt' 'roic v2' 'book price' 'sic' 'opInc' 'fcf yield'\n 'comStockEq' 'ms cem' 'total return' 'spitz roic' 'ms ce' 'momentum'] \n [0,6,7,8,9,10,12,13,15,16,17,18,19,20]\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Feature Names: \\n ['total yield' 'ms debt' 'roic v2' 'book price' 'sic' 'opInc' 'fcf yield'\\n 'comStockEq' 'ms cem' 'total return' 'spitz roic' 'ms ce' 'momentum'] \\n [0,6,7,8,9,10,12,13,15,16,17,18,19,20]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Feature Names: \n ['total yield' 'roic v2' 'book price' 'fcf yield' 'total return'\n 'spitz roic' 'momentum']\nFirst few Stocks with Features, no Lables:  \n [['DD' '0.03' '0.19' '0.16' '0.03' '0.09' '0.18' '0.93']\n ['DOW' '0.04' '0.13' '0.42' '0.03' '0.1' '0.13' '0.94']]  ...\n1436 Stocks by 8 Features\n"
     ]
    }
   ],
   "source": [
    "# Import all tradable stocks of 2015 (features X)\n",
    "import numpy as np\n",
    "import csv\n",
    "data = list(csv.reader(open('/Users/kimardenmiller/dropbox/tensorflow/data/x2015_noFinance.csv')))\n",
    "feature_data = np.asarray(data)\n",
    "# print('Example Stock with All Features: ', '\\n', feature_data[0:2,:], ' ...')  # First stock in X\n",
    "# First stock in X with selected features\n",
    "selected_features = feature_data[:,[0, 6, 8, 9, 13, 17, 18, 20]]  \n",
    "# print('Example Stock with Selected Features: ', '\\n', selected_features[0:2,:], ' ...')\n",
    "# X with selected features and labels & blanks removed\n",
    "x_data_features = selected_features[1:, :]\n",
    "x_data_features[x_data_features == ''] = 0.0\n",
    "x_data = x_data_features\n",
    "selected_feature_labels = selected_features[0, 1:]\n",
    "print('Selected Feature Names: \\n', selected_feature_labels)\n",
    "print('First few Stocks with Features, no Lables: ', '\\n', x_data[0:2, :], ' ...')\n",
    "print(np.size(x_data[:, 0]), 'Stocks by', np.size(x_data[0, :]), 'Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV shape:  (1437, 25)\nExample CVS Stock with All Features:  \n [['Ticker' 'Company' 'score' 'Close' 'Market Cap' 'Change 1M' 'total yield'\n  'ms debt' 'roic v2' 'book price' 'sic' 'price251ago' 'opInc' 'fcf yield'\n  'dolVol' 'comStockEq' 'ms cem' 'total return' 'spitz roic' 'ms ce'\n  'momentum' 'Sector' 'Industry' 'Description' 'rebalance']\n ['DD' 'E.I. du Pont de Nemours' '0' '69.26' '58553545945.41' '0.46' '0.03'\n  '11356000156.93' '0.19' '0.16' '16417999988.64' '64.86' '2892999992.35'\n  '0.03' '183223497.72' '9514000033.31' '5531999915.68' '0.09' '0.18'\n  '4452000010.73' '0.93' 'Basic Materials' 'Agriculture'\n  'A science and technology based company' 'False']]  ...\nZero lines: \n ['' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n '' '' '' '' '' '' '' '' '' '' '' '' '' '']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panda shape:  (1436, 25)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_data_values' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aec6205d7438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# print('Panda Nulls: ', x_import[x_import > 0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mpanda_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_import\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Panda shape: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_data_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Example Panda Stock with All Features: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpanda_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' ...'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# First stock in X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_data_values' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Test for Panda Import Fail\n",
    "import numpy as np\n",
    "import csv\n",
    "data = list(csv.reader(open('/Users/kimardenmiller/dropbox/tensorflow/data/x2015_noFinance.csv')))\n",
    "csv_data = np.asarray(data)\n",
    "print('CSV shape: ', csv_data.shape)\n",
    "print('Example CVS Stock with All Features: ', '\\n', csv_data[0:2, :], ' ...')  # First stock in X\n",
    "print('Zero lines: \\n', csv_data[csv_data == ''])\n",
    "\n",
    "import pandas\n",
    "x_import = pandas.read_csv('/Users/kimardenmiller/dropbox/tensorflow/data/x2015_noFinance.csv', header=0)\n",
    "print('Panda shape: ', x_import.shape)\n",
    "# print('Example Panda Pre Stock with All Features: ', '\\n', x_import)  # First stock in X\n",
    "x_import.fillna(value=0)\n",
    "# print('Panda Nulls: ', x_import[x_import > 0])\n",
    "panda_data = x_import.values\n",
    "print('Panda shape: ', x_data_values.shape)\n",
    "print('Example Panda Stock with All Features: ', '\\n', panda_data[0:2, :], ' ...')  # First stock in X\n",
    "\n",
    "# First stock in X with selected features\n",
    "selected_features = panda_data[:, [0, 6, 8, 9, 13, 17, 18, 20]]  \n",
    "# print('Example Stock with Selected Features: ', '\\n', selected_features[0:2,:], ' ...')\n",
    "# X with selected features and labels & blanks removed\n",
    "x_data_features = selected_features[1:, :]\n",
    "x_data_features[x_data_features == ''] = 0.0\n",
    "x_data = x_data_features\n",
    "selected_feature_labels = selected_features[0, 1:]\n",
    "print('Selected Feature Names: \\n', selected_feature_labels)\n",
    "print('First few Stocks with Features, no Labels: ', '\\n', x_data[0:2, :], ' ...')\n",
    "print(np.size(x_data[:, 0]), 'Stocks by', np.size(x_data[0,:]), 'Features')\n",
    "x_strings = x_data[:, 1:]  # take off tickers, as they can't be tensor'd\n",
    "raw_X = x_strings.astype(np.float)  # convert strings to float\n",
    "print('First few X Training Examples with', np.size(raw_X[0, :]), 'Selected Features: \\n', raw_X[0:2, :], ' ...')\n",
    "\n",
    "# A)  Standardize the X data (*** But this approach gives negatives, which is not good.)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(raw_X)\n",
    "std_rescaledX = scaler.transform(raw_X)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print('Pre Standardizing: \\n', raw_X[0:5, :])\n",
    "print('After Standardizing: \\n', std_rescaledX[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few Positive Examples:  \n [['AAPL' 'Apple, Inc.' 'NASD' 'Technology' 'Computer Hardware']\n ['ABAX' 'ABAXIS, Inc.' 'NASD' 'Health Care' 'Medical Supplies']\n ['ABC' 'AmerisourceBergen Corp.' 'NYSE' 'Consumer Staples'\n  'Drug Retailers']]  ...\nTotal Y Tickers:  237\nTotal Positive Y Ticker Example Count:  119\nTotal Positive Y Ticker Example Count on x_tickers:  119\nFirst few X Training Examples with 7 Selected Features: \n [[ 0.03  0.19  0.16  0.03  0.09  0.18  0.93]\n [ 0.04  0.13  0.42  0.03  0.1   0.13  0.94]]  ...\n"
     ]
    }
   ],
   "source": [
    "# Import best performing stocks of 2015 (y = 1)\n",
    "import csv\n",
    "data = list(csv.reader(open('/Users/kimardenmiller/dropbox/tensorflow/data/y201501_noFinancials.csv')))\n",
    "y_data = np.asarray(data[1:])\n",
    "print('First few Positive Examples: ', '\\n', y_data[0:3, 0:5], ' ...')\n",
    "# Find X and Y tickers\n",
    "x_tickers = x_data[:, 0]\n",
    "y_tickers = y_data[:, 0]\n",
    "print('Total Y Tickers: ', np.size(y_tickers))\n",
    "# Format Y to y = 1 (positive) and y = 0 (negative) examples \n",
    "true_false_mask = np.in1d(x_tickers, y_tickers)\n",
    "y_mask = np.where(true_false_mask, 1, 0)\n",
    "print('Total Positive Y Ticker Example Count: ', np.size(np.nonzero(y_mask)), )\n",
    "print('Total Positive Y Ticker Example Count on x_tickers: ', np.size(x_tickers[np.nonzero(y_mask)]))\n",
    "# Place dataset into input (X) and output (Y) variables\n",
    "x_strings = x_data[:, 1:]  # take off tickers, as they can't be tensor'd\n",
    "raw_X = x_strings.astype(np.float)  # convert strings to float\n",
    "Y = y_mask        # Y uses the 0, 1 to show negative and positive examples\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print('First few X Training Examples with', np.size(raw_X[0, :]) , 'Selected Features: \\n', raw_X[0:2, :], ' ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre Standardizing: \n [[ 0.03  0.19  0.16  0.03  0.09  0.18  0.93]\n [ 0.04  0.13  0.42  0.03  0.1   0.13  0.94]\n [ 0.09  0.2   0.1   0.04  0.1   0.2   0.88]\n [ 0.04  0.13  0.21  0.04 -0.01  0.13  0.92]\n [ 0.03  0.16  0.16  0.04  0.08  0.16  0.96]]\nAfter Standardizing: \n [[-0.424 -0.071 -0.563 -0.003 -0.024 -0.031  0.587]\n [-0.233 -0.122 -0.059 -0.003 -0.024 -0.053  0.662]\n [ 0.72  -0.062 -0.68   0.048 -0.024 -0.022  0.211]\n [-0.233 -0.122 -0.466  0.048 -0.025 -0.053  0.512]\n [-0.424 -0.097 -0.563  0.048 -0.024 -0.04   0.813]]\n"
     ]
    }
   ],
   "source": [
    "# A)  Standardize the X data (*** But this approach gives negatives, which is not good.)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(raw_X)\n",
    "std_rescaledX = scaler.transform(raw_X)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print('Pre Standardizing: \\n', raw_X[0:5, :])\n",
    "print('After Standardizing: \\n', std_rescaledX[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre scaling: \n",
      " [[ 0.03  0.19  0.16  0.03  0.09  0.18  0.93]\n",
      " [ 0.04  0.13  0.42  0.03  0.1   0.13  0.94]\n",
      " [ 0.09  0.2   0.1   0.04  0.1   0.2   0.88]\n",
      " [ 0.04  0.13  0.21  0.04 -0.01  0.13  0.92]\n",
      " [ 0.03  0.16  0.16  0.04  0.08  0.16  0.96]]\n",
      "After scaling: \n",
      " [[ 0.049  0.006  0.436  0.484  0.028  0.028  0.922]\n",
      " [ 0.066  0.004  0.457  0.484  0.028  0.028  0.933]\n",
      " [ 0.148  0.006  0.431  0.486  0.028  0.029  0.867]\n",
      " [ 0.066  0.004  0.44   0.486  0.028  0.028  0.911]\n",
      " [ 0.049  0.005  0.436  0.486  0.028  0.028  0.956]]\n"
     ]
    }
   ],
   "source": [
    "# B)  Rescale data (between 0 and 1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "range_rescaledX = scaler.fit_transform(raw_X)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "print('Pre scaling: \\n', raw_X[0:5, :])\n",
    "print('After scaling: \\n', range_rescaledX[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre scaling: \n",
      " [[ 0.03  0.19  0.16  0.03  0.09  0.18  0.93]\n",
      " [ 0.04  0.13  0.42  0.03  0.1   0.13  0.94]\n",
      " [ 0.09  0.2   0.1   0.04  0.1   0.2   0.88]\n",
      " [ 0.04  0.13  0.21  0.04 -0.01  0.13  0.92]\n",
      " [ 0.03  0.16  0.16  0.04  0.08  0.16  0.96]]\n",
      "After scaling: \n",
      " [[ 0.03   0.193  0.163  0.03   0.091  0.183  0.945]\n",
      " [ 0.038  0.124  0.399  0.029  0.095  0.124  0.894]\n",
      " [ 0.096  0.213  0.106  0.043  0.106  0.213  0.936]\n",
      " [ 0.042  0.135  0.218  0.042 -0.01   0.135  0.955]\n",
      " [ 0.03   0.159  0.159  0.04   0.08   0.159  0.957]]\n"
     ]
    }
   ],
   "source": [
    "# C)  Normalize data (length of 1)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer().fit(raw_X)\n",
    "normalizedX = scaler.transform(raw_X)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "print('Pre scaling: \\n', raw_X[0:5, :])\n",
    "print('After scaling: \\n', normalizedX[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(7, input_dim=7, init='uniform', activation='relu'))\n",
    "model.add(Dense(7, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre Feature Normalization: \n [[ 0.03  0.19  0.16  0.03  0.09  0.18  0.93]\n [ 0.04  0.13  0.42  0.03  0.1   0.13  0.94]\n [ 0.09  0.2   0.1   0.04  0.1   0.2   0.88]\n [ 0.04  0.13  0.21  0.04 -0.01  0.13  0.92]\n [ 0.03  0.16  0.16  0.04  0.08  0.16  0.96]]\nAfter Feature Normalization: \n [[ 0.03  0.19  0.16  0.03  0.09  0.18  0.93]\n [ 0.04  0.13  0.42  0.03  0.1   0.13  0.94]\n [ 0.09  0.2   0.1   0.04  0.1   0.2   0.88]\n [ 0.04  0.13  0.21  0.04 -0.01  0.13  0.92]\n [ 0.03  0.16  0.16  0.04  0.08  0.16  0.96]]\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'fbeta_score'])\n",
    "\n",
    "# Set any Feature Normalization\n",
    "X = raw_X  # Choices: std_rescaledX, range_rescaledX, normalizedX or just raw_X\n",
    "\n",
    "print('Pre Feature Normalization: \\n', raw_X[0:5, :])\n",
    "print('After Feature Normalization: \\n', X[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x113b92e80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, nb_epoch=600, batch_size=10, verbose=0)\n",
    "# model.fit(normalizedX, Y, nb_epoch=300, batch_size=10) # Change back to 150 after testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r  32/1436 [..............................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 256/1436 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 480/1436 [=========>....................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 704/1436 [=============>................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 928/1436 [==================>...........] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1184/1436 [=======================>......] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1436/1436 [==============================] - 0s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n loss: 26.62%\nacc: 91.71%\nfbeta_score: nan%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "# scores = model.evaluate(normalizedX, Y)\n",
    "print('\\n', \"%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[2], scores[2]*100))\n",
    "# print(model.metrics_names)\n",
    "# print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fist 100 Predictions:  \n [ 0.102  0.085  0.142  0.092  0.094  0.096  0.131  0.186  0.098  0.047\n  0.099  0.064  0.088  0.084  0.018  0.118  0.084  0.161  0.077  0.079\n  0.036  0.116  0.039  0.107  0.086  0.109  0.051  0.099  0.071  0.071\n  0.037  0.127  0.057  0.109  0.168  0.022  0.096  0.037  0.04   0.04   0.1\n  0.035  0.085  0.077  0.082  0.098  0.021  0.099  0.102  0.066  0.086\n  0.086  0.031  0.042  0.243  0.07   0.091  0.028  0.066  0.058  0.084\n  0.105  0.159  0.103  0.088  0.119  0.08   0.096  0.101  0.11   0.087\n  0.079  0.025  0.021  0.046  0.104  0.     0.072  0.067  0.063  0.071\n  0.122  0.082  0.068  0.092  0.     0.026  0.014  0.05   0.052  0.021\n  0.051  0.05   0.085  0.038  0.077  0.075  0.     0.045  0.026]\nRows in Prediction:  1436\nPositive Predictions:  2\nPositive Prediction Pointers:  \n (array([1155, 1178]),)\nPositive Prediction Tickers:  \n ['CHCT' 'GLW']\nPositive Prediction Tickers:  \n [['CHCT' 'Community Healthcare']\n ['GLW' 'Corning']]\nPositive Prediction Ground Truth:  \n [0 1]\nAccuracy of Positive Predictions:  \n 50.0%\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predictions = model.predict(X)\n",
    "# predictions = model.predict(normalizedX)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print('Fist 100 Predictions: ', '\\n', predictions[0:100, 0])\n",
    "print('Rows in Prediction: ', np.size(predictions[:, 0]))\n",
    "positive_predictions = np.sum(predictions[:, 0] > .5)\n",
    "print('Positive Predictions: ', positive_predictions)\n",
    "print('Positive Prediction Pointers: ', '\\n', np.where(predictions[:, 0] > .5))\n",
    "picks_data = feature_data[1:,:]\n",
    "print('Positive Prediction Tickers: ', '\\n', picks_data[np.where(predictions[:, 0] > .5), 0:2][0])\n",
    "print('Positive Prediction Ground Truth: ', '\\n', Y[np.where(predictions[:, 0] > .5)] )\n",
    "accurate_predictions = np.size(np.nonzero(Y[np.where(predictions[:, 0] > .5)]))\n",
    "print('Accuracy of Positive Predictions: ', '\\n', \"%.1f%%\" % ((accurate_predictions / positive_predictions) * 100 if positive_predictions > 0 else 0))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true,
   "summary": "Keras Sequential"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}